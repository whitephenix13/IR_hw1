{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 Code and Report\n",
    "AUFAR Rezka and LASBLEIS Alexandre "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Simulate Rankings of Relevance for E and P (5 points)\n",
    "\n",
    "In the first step you will generate pair s of rankings of relevance, for the production P and experimental E,\n",
    "respectively, for a hypothetical query q . Assume a 3-graded relevance, i.e. {N, R, HR}. Construct all\n",
    "possible P and E ranking pairs of length 5, for which E outperforms P.\n",
    "\n",
    "Example:<br>\n",
    "P: {N N N N N}<br>\n",
    "E: {N N N N R}<br>\n",
    "… <br>\n",
    "P: {HR HR HR HR R}<br>\n",
    "E: {HR HR HR HR HR}<br>\n",
    "\n",
    "(Note 1: If you do not have enough computational power, sample 1000 pair uniformly at random to show\n",
    "your work.)\n",
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert int to relevance\n",
    "#_list : list of integer to be converted\n",
    "#return : list of string where every integer has been replaced by its relevance interpretation\n",
    "def to_string(_list): \n",
    "    L=[]\n",
    "    for i in _list:\n",
    "        if i==0:\n",
    "            L.append(\"N \")\n",
    "        elif i==1:\n",
    "            L.append(\"R \")\n",
    "        elif i==2:\n",
    "            L.append(\"HR\")\n",
    "        else: \n",
    "            L.append(\"? \")\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = [] #variable used to store all pairs \n",
    "Ps = []\n",
    "Es = []\n",
    "\n",
    "#Create all combinaison for P, there are 3^5 = 243 possibilities since P is of length 5 and each member have 3 possible values:\n",
    "# 0 (representing \"N\" ), 1 (representing \"R), 2 (representing \"HR)\n",
    "for p_possibility in range(243): \n",
    "    P=[None]*5\n",
    "    #create all five values for P \n",
    "    for p_pos in range(5):\n",
    "        P[p_pos]= p_possibility // (np.power(3,p_pos)) %3 #formula to create all combinaison\n",
    "    #we do the same for E    \n",
    "    for e_possibility in range(243): \n",
    "        E=[None]*5\n",
    "        for e_pos in range(5):\n",
    "            E[e_pos]= e_possibility // (np.power(3,e_pos)) %3 #formula to create all combinaison\n",
    "        pairs.append((P,E)) #adding the pair since every pair is valid\n",
    "        #Memorize all created Es but only once\n",
    "        if p_possibility==0:\n",
    "            Es.append(E)\n",
    "        #memorize all created Ps\n",
    "    Ps.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59049\n",
      "P:  ['N ', 'R ', 'N ', 'R ', 'N '] E:  ['N ', 'R ', 'R ', 'HR', 'HR']\n",
      "243\n",
      "[[0, 0, 0, 0, 0], [1, 0, 0, 0, 0], [2, 0, 0, 0, 0], [0, 1, 0, 0, 0], [1, 1, 0, 0, 0], [2, 1, 0, 0, 0], [0, 2, 0, 0, 0], [1, 2, 0, 0, 0], [2, 2, 0, 0, 0], [0, 0, 1, 0, 0], [1, 0, 1, 0, 0], [2, 0, 1, 0, 0], [0, 1, 1, 0, 0], [1, 1, 1, 0, 0], [2, 1, 1, 0, 0], [0, 2, 1, 0, 0], [1, 2, 1, 0, 0], [2, 2, 1, 0, 0], [0, 0, 2, 0, 0], [1, 0, 2, 0, 0], [2, 0, 2, 0, 0], [0, 1, 2, 0, 0], [1, 1, 2, 0, 0], [2, 1, 2, 0, 0], [0, 2, 2, 0, 0], [1, 2, 2, 0, 0], [2, 2, 2, 0, 0], [0, 0, 0, 1, 0], [1, 0, 0, 1, 0], [2, 0, 0, 1, 0], [0, 1, 0, 1, 0], [1, 1, 0, 1, 0], [2, 1, 0, 1, 0], [0, 2, 0, 1, 0], [1, 2, 0, 1, 0], [2, 2, 0, 1, 0], [0, 0, 1, 1, 0], [1, 0, 1, 1, 0], [2, 0, 1, 1, 0], [0, 1, 1, 1, 0], [1, 1, 1, 1, 0], [2, 1, 1, 1, 0], [0, 2, 1, 1, 0], [1, 2, 1, 1, 0], [2, 2, 1, 1, 0], [0, 0, 2, 1, 0], [1, 0, 2, 1, 0], [2, 0, 2, 1, 0], [0, 1, 2, 1, 0], [1, 1, 2, 1, 0], [2, 1, 2, 1, 0], [0, 2, 2, 1, 0], [1, 2, 2, 1, 0], [2, 2, 2, 1, 0], [0, 0, 0, 2, 0], [1, 0, 0, 2, 0], [2, 0, 0, 2, 0], [0, 1, 0, 2, 0], [1, 1, 0, 2, 0], [2, 1, 0, 2, 0], [0, 2, 0, 2, 0], [1, 2, 0, 2, 0], [2, 2, 0, 2, 0], [0, 0, 1, 2, 0], [1, 0, 1, 2, 0], [2, 0, 1, 2, 0], [0, 1, 1, 2, 0], [1, 1, 1, 2, 0], [2, 1, 1, 2, 0], [0, 2, 1, 2, 0], [1, 2, 1, 2, 0], [2, 2, 1, 2, 0], [0, 0, 2, 2, 0], [1, 0, 2, 2, 0], [2, 0, 2, 2, 0], [0, 1, 2, 2, 0], [1, 1, 2, 2, 0], [2, 1, 2, 2, 0], [0, 2, 2, 2, 0], [1, 2, 2, 2, 0], [2, 2, 2, 2, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1], [2, 0, 0, 0, 1], [0, 1, 0, 0, 1], [1, 1, 0, 0, 1], [2, 1, 0, 0, 1], [0, 2, 0, 0, 1], [1, 2, 0, 0, 1], [2, 2, 0, 0, 1], [0, 0, 1, 0, 1], [1, 0, 1, 0, 1], [2, 0, 1, 0, 1], [0, 1, 1, 0, 1], [1, 1, 1, 0, 1], [2, 1, 1, 0, 1], [0, 2, 1, 0, 1], [1, 2, 1, 0, 1], [2, 2, 1, 0, 1], [0, 0, 2, 0, 1], [1, 0, 2, 0, 1], [2, 0, 2, 0, 1], [0, 1, 2, 0, 1], [1, 1, 2, 0, 1], [2, 1, 2, 0, 1], [0, 2, 2, 0, 1], [1, 2, 2, 0, 1], [2, 2, 2, 0, 1], [0, 0, 0, 1, 1], [1, 0, 0, 1, 1], [2, 0, 0, 1, 1], [0, 1, 0, 1, 1], [1, 1, 0, 1, 1], [2, 1, 0, 1, 1], [0, 2, 0, 1, 1], [1, 2, 0, 1, 1], [2, 2, 0, 1, 1], [0, 0, 1, 1, 1], [1, 0, 1, 1, 1], [2, 0, 1, 1, 1], [0, 1, 1, 1, 1], [1, 1, 1, 1, 1], [2, 1, 1, 1, 1], [0, 2, 1, 1, 1], [1, 2, 1, 1, 1], [2, 2, 1, 1, 1], [0, 0, 2, 1, 1], [1, 0, 2, 1, 1], [2, 0, 2, 1, 1], [0, 1, 2, 1, 1], [1, 1, 2, 1, 1], [2, 1, 2, 1, 1], [0, 2, 2, 1, 1], [1, 2, 2, 1, 1], [2, 2, 2, 1, 1], [0, 0, 0, 2, 1], [1, 0, 0, 2, 1], [2, 0, 0, 2, 1], [0, 1, 0, 2, 1], [1, 1, 0, 2, 1], [2, 1, 0, 2, 1], [0, 2, 0, 2, 1], [1, 2, 0, 2, 1], [2, 2, 0, 2, 1], [0, 0, 1, 2, 1], [1, 0, 1, 2, 1], [2, 0, 1, 2, 1], [0, 1, 1, 2, 1], [1, 1, 1, 2, 1], [2, 1, 1, 2, 1], [0, 2, 1, 2, 1], [1, 2, 1, 2, 1], [2, 2, 1, 2, 1], [0, 0, 2, 2, 1], [1, 0, 2, 2, 1], [2, 0, 2, 2, 1], [0, 1, 2, 2, 1], [1, 1, 2, 2, 1], [2, 1, 2, 2, 1], [0, 2, 2, 2, 1], [1, 2, 2, 2, 1], [2, 2, 2, 2, 1], [0, 0, 0, 0, 2], [1, 0, 0, 0, 2], [2, 0, 0, 0, 2], [0, 1, 0, 0, 2], [1, 1, 0, 0, 2], [2, 1, 0, 0, 2], [0, 2, 0, 0, 2], [1, 2, 0, 0, 2], [2, 2, 0, 0, 2], [0, 0, 1, 0, 2], [1, 0, 1, 0, 2], [2, 0, 1, 0, 2], [0, 1, 1, 0, 2], [1, 1, 1, 0, 2], [2, 1, 1, 0, 2], [0, 2, 1, 0, 2], [1, 2, 1, 0, 2], [2, 2, 1, 0, 2], [0, 0, 2, 0, 2], [1, 0, 2, 0, 2], [2, 0, 2, 0, 2], [0, 1, 2, 0, 2], [1, 1, 2, 0, 2], [2, 1, 2, 0, 2], [0, 2, 2, 0, 2], [1, 2, 2, 0, 2], [2, 2, 2, 0, 2], [0, 0, 0, 1, 2], [1, 0, 0, 1, 2], [2, 0, 0, 1, 2], [0, 1, 0, 1, 2], [1, 1, 0, 1, 2], [2, 1, 0, 1, 2], [0, 2, 0, 1, 2], [1, 2, 0, 1, 2], [2, 2, 0, 1, 2], [0, 0, 1, 1, 2], [1, 0, 1, 1, 2], [2, 0, 1, 1, 2], [0, 1, 1, 1, 2], [1, 1, 1, 1, 2], [2, 1, 1, 1, 2], [0, 2, 1, 1, 2], [1, 2, 1, 1, 2], [2, 2, 1, 1, 2], [0, 0, 2, 1, 2], [1, 0, 2, 1, 2], [2, 0, 2, 1, 2], [0, 1, 2, 1, 2], [1, 1, 2, 1, 2], [2, 1, 2, 1, 2], [0, 2, 2, 1, 2], [1, 2, 2, 1, 2], [2, 2, 2, 1, 2], [0, 0, 0, 2, 2], [1, 0, 0, 2, 2], [2, 0, 0, 2, 2], [0, 1, 0, 2, 2], [1, 1, 0, 2, 2], [2, 1, 0, 2, 2], [0, 2, 0, 2, 2], [1, 2, 0, 2, 2], [2, 2, 0, 2, 2], [0, 0, 1, 2, 2], [1, 0, 1, 2, 2], [2, 0, 1, 2, 2], [0, 1, 1, 2, 2], [1, 1, 1, 2, 2], [2, 1, 1, 2, 2], [0, 2, 1, 2, 2], [1, 2, 1, 2, 2], [2, 2, 1, 2, 2], [0, 0, 2, 2, 2], [1, 0, 2, 2, 2], [2, 0, 2, 2, 2], [0, 1, 2, 2, 2], [1, 1, 2, 2, 2], [2, 1, 2, 2, 2], [0, 2, 2, 2, 2], [1, 2, 2, 2, 2], [2, 2, 2, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "print(len(pairs)) #= 59049 which is equal to the expected length = 3 ^10 = 59049\n",
    "#print(pairs) #print all pairs but this takes a lot of place\n",
    "\n",
    "#print a random pair to show that it makes sense \n",
    "r = rand.randint(0,59049-1)\n",
    "print(\"P: \" , to_string(pairs[r][0]), \"E: \",to_string(pairs[r][1]))\n",
    "\n",
    "#check if Es is as expected \n",
    "print(len(Es))#expect 243 = 3^5 \n",
    "print(Es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanations\n",
    "In order to contruct all possible pairs of P and E with a 3-graded relevance {N, R, HR}, we first encode those relevance as integers: <br>\n",
    "* 0 for N <br>\n",
    "* 1 for R <br>\n",
    "* 2 for HR <br>\n",
    "This encoding allows us to do easy comparison between elements.\n",
    "Then we created all pairs using this formula : $value = \\frac{possibility}{3^{pos}} [3]$ with $possibility \\in \\{0,...,243\\}$ and $ pos \\in \\{0,1,2,3,4\\}$.\n",
    "\n",
    "This give the following sequence depending on the position of the element in the list: <br>\n",
    "* 0: $\\{0,1,2,0,1,2,0,1,2,0,1,2...\\}$\n",
    "* 1: $\\{0,0,0,1,1,1,2,2,2,0,0,0...\\}$\n",
    "* 2: $\\{0,0,0,0,0,0,0,0,0,1,1,1,...\\}$\n",
    "* ... and so on\n",
    "\n",
    "This formula is then used for the production P and the experiment E. \n",
    "\n",
    "##### Analysis\n",
    "According to the formula we showed before, we should find all the possible combination. Futhermore, the number of pairs found is equal to the one we expected $3^{10}$ and the number of E and P are $3^{5}$ each which is also what is expected. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2 : Implement Evaluation Measures (15 points)\n",
    "\n",
    "Implement 1 binary and 2 multi-graded evaluation measures out of the 7 measures mentioned above.\n",
    "\n",
    "(Note 2: Some of the aforementioned measures require the total number of relevant and highly relevant\n",
    "documents in the entire collection – pay extra attention on how to find this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Remove for evaluation \n",
    "\n",
    "#Recall at rank k \n",
    "def Binary_measure_recal(test_set, r):\n",
    "    num_test_rel = 0 \n",
    "    total_num_rel=0\n",
    "    for i in range(len(test_set)):\n",
    "        if test_set[i]>0:\n",
    "            if i<r:\n",
    "                num_test_rel+=1\n",
    "            total_num_rel+=1\n",
    "    return float(num_test_rel) / total_num_rel\n",
    "\n",
    "#Average precision at rank k \n",
    "def Binary_measure_avg_precision(test_set, r):\n",
    "    num_rel=0\n",
    "    sum_precision = 0 \n",
    "    total_num_rel=0\n",
    "    temp=\"(\"\n",
    "    for i in range(len(test_set)):\n",
    "        if test_set[i]>0:\n",
    "            if i<r:\n",
    "                num_rel+=1\n",
    "                temp+=\" \"+str(num_rel)+\"/\"+str(i+1)+\"+\"\n",
    "                sum_precision+=float(num_rel)/(i+1)\n",
    "            total_num_rel+=1\n",
    "    temp=temp[:len(temp)-1]+\")\"\n",
    "    #print(temp,\"/\",total_num_rel)\n",
    "    return float(sum_precision) / total_num_rel\n",
    "#Normalized discount cumulative gain nDCG at rank r\n",
    "def nDCG(test_set, r):\n",
    "    orderedSet= list(test_set)\n",
    "    orderedSet.sort(reverse=True)\n",
    "    return DCG(test_set, r) / DCG(orderedSet, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BINARY \n",
    "#Precision at rank r \n",
    "#test_set: the collection to be tested \n",
    "#r: the rank for which we test the collection \n",
    "#return : the precision \n",
    "def Binary_measure_precision(test_set, r):\n",
    "    assert r <= len(test_set)\n",
    "    assert r!= 0\n",
    "    num_test_rel = 0 \n",
    "    for i in range(r):\n",
    "        #According to our notation, if test_set[i]>0, the document is relevant\n",
    "        if test_set[i]>0:\n",
    "            num_test_rel+=1\n",
    "    return float(num_test_rel) / r #precision is number of relevant doc/ number of doc considered\n",
    "\n",
    "#MULTI GRADED \n",
    "#Discount cumulative gain DCG at rank r\n",
    "#test_set: the collection to be tested \n",
    "#r: the rank for which we test the collection \n",
    "#return : the gain \n",
    "def DCG(test_set, r):\n",
    "    assert r <= len(test_set)\n",
    "    assert r!= 0\n",
    "    res=0\n",
    "    for k in range(1,r+1):#r is the rank so it starts at 1\n",
    "        rel_r = test_set[k-1]#index of element = rank -1 since rank starts at 1 and index at 0\n",
    "        res+=float(np.power(2,rel_r)-1)/(np.log2(1+k))\n",
    "    return res\n",
    "\n",
    "#Rank Biased Precision w ith persistence parameter 𝜃 =0.8\n",
    "#test_set: the collection to be tested \n",
    "#theta: the theta parameter of the RBP formula\n",
    "#return : the precision\n",
    "def RBP (test_set,theta=0.8):\n",
    "    res=0\n",
    "    for k in range(1,len(test_set)+1):\n",
    "        rel_k=test_set[k-1]\n",
    "        res+= rel_k * np.power(theta,k-1) * (1.0-theta)\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific ordering\n",
      "Rank =  1 Precision 1.0 DCG 1.0 RBP 1.06\n",
      "Rank =  2 Precision 0.5 DCG 1.0 RBP 1.06\n",
      "Rank =  3 Precision 0.667 DCG 2.5 RBP 1.06\n",
      "Rank =  4 Precision 0.75 DCG 15.851 RBP 1.06\n",
      "Rank =  5 Precision 0.6 DCG 15.851 RBP 1.06\n",
      "Rank =  6 Precision 0.667 DCG 16.207 RBP 1.06\n",
      "Rank =  7 Precision 0.571 DCG 16.207 RBP 1.06\n",
      "Rank =  8 Precision 0.5 DCG 16.207 RBP 1.06\n",
      "Rank =  9 Precision 0.444 DCG 16.207 RBP 1.06\n",
      "Rank =  10 Precision 0.5 DCG 16.496 RBP 1.06\n",
      "\n",
      "Perfect ordering\n",
      "Rank =  1 Precision 1.0 DCG 31.0 RBP 1.632\n",
      "Rank =  2 Precision 1.0 DCG 32.893 RBP 1.632\n",
      "Rank =  3 Precision 1.0 DCG 33.393 RBP 1.632\n",
      "Rank =  4 Precision 1.0 DCG 33.823 RBP 1.632\n",
      "Rank =  5 Precision 1.0 DCG 34.21 RBP 1.632\n",
      "Rank =  6 Precision 0.833 DCG 34.21 RBP 1.632\n",
      "Rank =  7 Precision 0.714 DCG 34.21 RBP 1.632\n",
      "Rank =  8 Precision 0.625 DCG 34.21 RBP 1.632\n",
      "Rank =  9 Precision 0.556 DCG 34.21 RBP 1.632\n",
      "Rank =  10 Precision 0.5 DCG 34.21 RBP 1.632\n",
      "\n",
      "Worst ordering\n",
      "Rank =  1 Precision 0.0 DCG 0.0 RBP 0.361\n",
      "Rank =  2 Precision 0.0 DCG 0.0 RBP 0.361\n",
      "Rank =  3 Precision 0.0 DCG 0.0 RBP 0.361\n",
      "Rank =  4 Precision 0.0 DCG 0.0 RBP 0.361\n",
      "Rank =  5 Precision 0.0 DCG 0.0 RBP 0.361\n",
      "Rank =  6 Precision 0.167 DCG 0.356 RBP 0.361\n",
      "Rank =  7 Precision 0.286 DCG 0.69 RBP 0.361\n",
      "Rank =  8 Precision 0.375 DCG 1.005 RBP 0.361\n",
      "Rank =  9 Precision 0.444 DCG 1.908 RBP 0.361\n",
      "Rank =  10 Precision 0.5 DCG 10.869 RBP 0.361\n"
     ]
    }
   ],
   "source": [
    "test=        [1,0,2,5,0,1,0,0,0,1]#length 10\n",
    "test_perfect=[5,2,1,1,1,0,0,0,0,0]\n",
    "test_worst=  [0,0,0,0,0,1,1,1,2,5]\n",
    "\n",
    "#The following results are rounded in order to make them readable\n",
    "#Specific ordering \n",
    "print(\"Specific ordering\")\n",
    "for r in range(1,len(test)+1):\n",
    "    print('Rank = ' , r,'Precision',round(Binary_measure_precision(test,r),3),'DCG', round(DCG(test,r),3),\n",
    "          'RBP', round(RBP(test),3))\n",
    "\n",
    "#Perfect ordering \n",
    "print(\"\\nPerfect ordering\")\n",
    "for r in range(1,len(test_perfect)+1):\n",
    "    print('Rank = ' , r,'Precision',round(Binary_measure_precision(test_perfect,r),3),'DCG', round(DCG(test_perfect,r),3),\n",
    "          'RBP', round(RBP(test_perfect),3))\n",
    "\n",
    "#Worst ordering \n",
    "print(\"\\nWorst ordering\")\n",
    "for r in range(1,len(test_worst)+1):\n",
    "    print('Rank = ' , r,'Precision',round(Binary_measure_precision(test_worst,r),3),'DCG', round(DCG(test_worst,r),3),\n",
    "          'RBP', round(RBP(test_worst),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanations\n",
    "For Precision and DCG, we need to ensure that rank k does not exceed the documents length, and k cannot be zero.<br>\n",
    "For DCG and RBP, we also decided that the value of the relevant would be equal to the value at that rank in the list. For example if an example is extremely relevant, he might get a value of 5 (as in the example) which leads to higher gain in DCG than a document which is only highly relevant (value of 2).<br>\n",
    "Otherwise our implementation follows the definition of the method. \n",
    "\n",
    "##### Analysis\n",
    "The result for Precision is highly dependant on the number of non-relevant in the cut-off collection. As k increases, the more non-relevant exists in the cut-off, the lower the precision will be. If we consider a rank equal to the length of the list, the precision is the same whatever the order is. Precision does not that into account how good the relevance of a document is, it only cares if a document is relevant or not. \n",
    "\n",
    "For DCG, the result depends on the degree of the relevance and the order of it. If the highest relevant score exists in the first position of the cut-off, the higher DCG will be. We showed that by displaying the DCG score with perfect ordering which is higher at any rank than the \"specific ordering\". Those value may be hard to use to compare different collections due to the fact that it is sensitive to the degree of relevance. A way to cope with that problem is to use its alternative version: the nDCG (normalized version). \n",
    "\n",
    "For RBP, we disregard rank and therefore we have the same result no matter the rank is. This measure pays great attention to the ordering as shown above: the best score is obtained with a perfect ordering whereas the worst one is obtained with the worst ordering. The model behind RBP considers \n",
    "\n",
    "TODO....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Calculate the measure (5 points)\n",
    "\n",
    "For the three measures and all P and E ranking pairs constructed above calculate the difference: 𝛥measure\n",
    "= measure E -measure P . Consider only those pairs for which E outperforms P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def outperforms(methond_name,E,P,rank):\n",
    "    if methond_name==\"precision\":\n",
    "        delta = Binary_measure_precision(E,rank)-Binary_measure_precision(P,rank)\n",
    "        return (delta>0), delta \n",
    "    elif methond_name==\"DCG\":\n",
    "        delta=DCG(E,rank)-DCG(P,rank)\n",
    "        return (delta>0), delta \n",
    "    elif methond_name==\"RBP\":\n",
    "        delta=RBP(E)-RBP(P)\n",
    "        return (delta>0), delta \n",
    "        \n",
    "#Measures chosen : precision, DCG, RBP \n",
    "outperf_pairs_prec=[]\n",
    "pairs_set_prec = []\n",
    "d_measure_prec=[]\n",
    "\n",
    "outperf_pairs_DCG=[]\n",
    "pairs_set_DCG = []\n",
    "d_measure_DCG=[]\n",
    "\n",
    "outperf_pairs_RBP=[]\n",
    "pairs_set_RBP = []\n",
    "d_measure_RBP=[]\n",
    "\n",
    "rank = 4\n",
    "for i in range(len(pairs)):#pairs made of (P,E)\n",
    "    outperforms_prec,delta_prec= outperforms(\"precision\",pairs[i][1],pairs[i][0],rank)\n",
    "    outperforms_DCG,delta_DCG= outperforms(\"DCG\",pairs[i][1],pairs[i][0],rank)\n",
    "    outperforms_RBP,delta_RBP= outperforms(\"RBP\",pairs[i][1],pairs[i][0],rank)\n",
    "\n",
    "    if(outperforms_prec):\n",
    "        outperf_pairs_prec.append(pairs[i])\n",
    "        temp = pairs[i][1] + pairs[i][0]\n",
    "        pairs_set_prec.append(''.join(str(x) for x in temp))\n",
    "        d_measure_prec.append(delta_prec)\n",
    "        \n",
    "    if(outperforms_DCG):\n",
    "        outperf_pairs_DCG.append(pairs[i])\n",
    "        temp = pairs[i][1] + pairs[i][0]\n",
    "        pairs_set_DCG.append(''.join(str(x) for x in temp))\n",
    "        d_measure_DCG.append(delta_DCG)\n",
    "        \n",
    "    if(outperforms_RBP):\n",
    "        outperf_pairs_RBP.append(pairs[i])\n",
    "        temp = pairs[i][1] + pairs[i][0]\n",
    "        pairs_set_RBP.append(''.join(str(x) for x in temp))\n",
    "        d_measure_RBP.append(delta_RBP)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-5c65626e0903>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-5c65626e0903>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print len(set.intersection(set(pairs_set_prec), set(pairs_set_DCG), set(pairs_set_RBP)))\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "length = min(100,len(outperf_pairs_prec))\n",
    "#print len(outperf_pairs_prec)\n",
    "#print len(outperf_pairs_DCG)\n",
    "#print len(outperf_pairs_RBP)\n",
    "\n",
    "print len(set.intersection(set(pairs_set_prec), set(pairs_set_DCG), set(pairs_set_RBP)))\n",
    "print rand.sample(set.intersection(set(pairs_set_prec), set(pairs_set_DCG)),1)\n",
    "\n",
    "# pick result that is in prec but is not in DCG\n",
    "print rand.sample(set(pairs_set_prec) - set(pairs_set_DCG),1)\n",
    "# pick result that is in DCG but is not in prec\n",
    "print rand.sample(set(pairs_set_prec) - set(pairs_set_DCG),1)\n",
    "\n",
    "#for j in range(length):\n",
    "#    print(\"P:\",to_string(outperf_pairs_prec[j][0]),\"E:\",to_string(outperf_pairs_prec[j][1]))\n",
    "#    print(d_measure_prec[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanations\n",
    "For precision, DCG, and RBP, we calculate the difference between all combination of E and P that we have generated in Step 1, then we append every difference that is greater than zero, which means that E outperforms P.\n",
    "##### Analysis\n",
    "For each three measures, we have different pairs in which E outperforms P. There are 17184 pairs which E outperforms P in all three measures have. However, there exists some pairs which the measures does not yield the same answer. <br> \n",
    "For example, E=[0,1,1,1,0] outperforms P=[1,0,2,0,0] in precision, but not in DCG. E=[1,2,0,0,1] outperforms P=[2,0,0,0,2] in DCG, but not in precision. <br>\n",
    "This indicates that in real world application, it is important to implement different kinds of measure so we will have broader feedback to optimize the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
